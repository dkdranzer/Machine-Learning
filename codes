#linear regression
def estimate_coef(x,y):
  n=np.size(x)
  mean_x=np.mean(x)
  mean_y=np.mean(y)

  meanx_mean_y=mean_x*mean_y

  mean_xy=np.mean(x*y)

  mean_xs=np.mean(x*x)
  sq_mean=mean_x*mean_x

  b_1=(mean_xy-meanx_mean_y)/(mean_xs-sq_mean)
  b_0=mean_y-b_1*mean_x

  return (b_0,b_1)


def plot_regression_line(x,y,b):
    plt.scatter(x,y,color="m",marker="o",s=30)

    y_pred=b[0]+b[1]*x

    plt.plot(x,y_pred,color="g")

    plt.xlabel('YearsExperience')
    plt.ylabel('Salary')
    plt.show()

def main():
    data=pd.read_csv("/content/Salary_Data.csv")
    x=data["YearsExperience"]
    y=data["Salary"]
    b=estimate_coef(x,y)
    print("Estimated coefficients:b_0={} \nb_1={}".format(b[0],b[1]))
    plot_regression_line(x,y,b)
main()

# multiple
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

class LinearRegression:
    def __init__(self, learning_rate=0.01, n_iters=1000):
        self.lr = learning_rate
        self.n_iters = n_iters
        self.weights = None
        self.bias = None

    def fit(self, X, y):
        n_samples, n_features = X.shape
        self.weights = np.zeros((n_features, 1))
        self.bias = 0

        for _ in range(self.n_iters):
            y_pred = np.dot(X, self.weights) + self.bias

            dw = (1 / n_samples) * np.dot(X.T, (y_pred - y))
            db = (1 / n_samples) * np.sum(y_pred - y)

            self.weights -= self.lr * dw
            self.bias -= self.lr * db

    def predict(self, X):
        return np.dot(X, self.weights) + self.bias

if __name__ == "__main__":
    # Load data
    df = pd.read_csv("/content/Salary_dataset.csv")

    X = df[["YearsExperience"]].values
    y = df[["Salary"]].values

    model = LinearRegression(learning_rate=0.05, n_iters=2000)
    model.fit(X, y)
    predictions = model.predict(X)

    # Metrics
    mse = mean_squared_error(y, predictions)
    mae = mean_absolute_error(y, predictions)
    r2 = r2_score(y, predictions)

    print(f"Weights: {model.weights.flatten()}")
    print(f"Bias: {model.bias}")
    print(f"Mean Squared Error: {mse:.4f}")
    print(f"Mean Absolute Error: {mae:.4f}")
    print(f"R-squared: {r2:.4f}")

    # Plot
    sort_idx = X[:, 0].argsort()
    X_sorted = X[sort_idx]
    predictions_sorted = predictions[sort_idx]

    plt.scatter(X, y, color='blue', label='Actual data')
    plt.plot(X_sorted, predictions_sorted, color='red', label='Prediction')
    plt.xlabel("YearsExperience")
    plt.ylabel("Salary")
    plt.legend()
    plt.show()



# multiple
import pandas as pd
import numpy as np

# Step 1: Load the dataset
df = pd.read_csv('Student_Performance.csv')

# Step 2: Preprocess the data
# Encode 'Extracurricular Activities' column: Yes -> 1, No -> 0
df['Extracurricular Activities'] = df['Extracurricular Activities'].map({'Yes': 1, 'No': 0})

# Define feature columns and target variable
feature_cols = [
    'Hours Studied',
    'Previous Scores',
    'Extracurricular Activities',
    'Sleep Hours',
    'Sample Question Papers Practiced'
]
target_col = 'Performance Index'

# Extract features and target from the dataframe
X = df[feature_cols].astype(float).values
Y = df[target_col].astype(float).values

# Add an intercept term to the features
X = np.column_stack((np.ones(X.shape[0]), X))

# Step 3: Compute regression coefficients using the normal equation
XtX = X.T @ X
XtX_inv = np.linalg.inv(XtX)
XtY = X.T @ Y
beta = XtX_inv @ XtY

# Step 4: Make predictions
Y_pred = X @ beta

# Calculate evaluation metrics
mse = np.mean((Y - Y_pred) ** 2)
rss = np.sum((Y - Y_pred) ** 2)
tss = np.sum((Y - np.mean(Y)) ** 2)
r_squared = 1 - (rss / tss)

# Output the results
print("Model Coefficients (including intercept):", beta)
print(f"Mean Squared Error (MSE): {mse:.2f}")
print(f"R-squared (RÂ²): {r_squared:.4f}")



logistic-
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# Step 1: Load the dataset
df = pd.read_csv('diabetes2.csv')  # Make sure the file is in your working directory

# Step 2: Define features and target
feature_cols = [
    'Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness',
    'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age'
]
target_col = 'Outcome'

X = df[feature_cols].astype(float).values
Y = df[target_col].values

# Add intercept term
X = np.column_stack((np.ones(X.shape[0]), X))

# Step 3: Compute coefficients via normal equation
XtX = X.T @ X
XtX_inv = np.linalg.inv(XtX)
XtY = X.T @ Y
beta = XtX_inv @ XtY

# Step 4: Predict linear values and apply sigmoid
def sigmoid(z):
    return 1 / (1 + np.exp(-z))

linear_preds = X @ beta
prob_preds = sigmoid(linear_preds)

# Step 5: Convert probabilities to binary predictions
binary_preds = (prob_preds >= 0.5).astype(int)

# Step 6: Compute evaluation metrics
accuracy = np.mean(binary_preds == Y)
tp = np.sum((binary_preds == 1) & (Y == 1))
tn = np.sum((binary_preds == 0) & (Y == 0))
fp = np.sum((binary_preds == 1) & (Y == 0))
fn = np.sum((binary_preds == 0) & (Y == 1))

precision = tp / (tp + fp + 1e-8)
recall = tp / (tp + fn + 1e-8)
f1 = 2 * precision * recall / (precision + recall + 1e-8)

print("Model Coefficients (including intercept):", beta)
print(f"Accuracy: {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1 Score: {f1:.4f}")

# Step 7: Plot sigmoid curve
z = np.linspace(-10, 10, 200)
sigmoid_values = sigmoid(z)

plt.figure(figsize=(8, 5))
plt.plot(z, sigmoid_values, label='Sigmoid function', color='blue')
plt.title('Sigmoid Curve')
plt.xlabel('Input (z)')
plt.ylabel('Sigmoid(z)')
plt.grid(True)
plt.legend()
plt.show()


decision tree-
import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
eps = np.finfo(float).eps
from numpy import log2 as log

df=pd.read_csv('/content/play_tennis.csv')
df = df.drop('day',axis=1)
df.head()
df.describe()
def find_entropy(df):
  target=df.keys()[-1] #to get target column name .keys will return all col names when -1 means last name
  entropy=0
  values=df[target].unique() #all unique values in target col
  for value in values:
    fraction=df[target].value_counts()[value]/len(df[target])
    entropy+=-fraction*np.log2(fraction)
  return entropy

print(find_entropy(df))

def average_information(df,attribute):
  target = df.keys()[-1]   #target column
  target_variables = df[target].unique()  #This gives all 'Yes' and 'No'
  variables = df[attribute].unique()    #This gives different features in that attribute (like 'Hot','Cold' in Temperature)
  entropy2 = 0
  for variable in variables:
      entropy = 0
      for target_variable in target_variables:
          num = len(df[attribute][df[attribute]==variable][df[target] ==target_variable])
          den = len(df[attribute][df[attribute]==variable])
          fraction = num/(den+eps)
          entropy += -fraction*log(fraction+eps)
      fraction2 = den/len(df)
      entropy2 += -fraction2*entropy
  return abs(entropy2)

def find_winner(df):
    IG = []
    for key in df.keys()[:-1]:
        IG.append(find_entropy(df)-average_information(df,key))
    return df.keys()[:-1][np.argmax(IG)]
def get_subtable(df, node,value):
  return df[df[node] == value].reset_index(drop=True)

def buildTree(df,tree=None):
    target = df.keys()[-1]   #target column

    #Here we build our decision tree

    #Get attribute with maximum information gain
    node = find_winner(df)

    #Get distinct value of that attribute e.g Salary is node and Low,Med and High are values
    attValue = np.unique(df[node])

    #Create an empty dictionary to create tree
    if tree is None:
        tree={}
        tree[node] = {}

    #We make loop to construct a tree by calling this function recursively.
    #In this we check if the subset is pure and stops if it is pure.

    for value in attValue:

        subtable = get_subtable(df,node,value)
        clValue,counts = np.unique(subtable[target],return_counts=True)

        if len(counts)==1:#Checking purity of subset
            tree[node][value] = clValue[0]
        else:
            tree[node][value] = buildTree(subtable) #Calling the function recursively

    return tree
tree = buildTree(df)
def predict(tree, sample):
    """
    Traverse the decision tree to predict the class of a given sample.
    - tree: The decision tree (nested dictionary)
    - sample: Dictionary of attribute values for the sample
    """
    if not isinstance(tree, dict):
        return tree  # Leaf node, return class label

    root_node = next(iter(tree))  # Get the first (root) attribute
    if sample[root_node] in tree[root_node]:  # Check if sample has that attribute value
        return predict(tree[root_node][sample[root_node]], sample)
    else:
        return "Unknown"
test_sample1 = {'outlook': 'Sunny', 'temp': 'Cool', 'humidity': 'High', 'wind': 'Strong'}
prediction1 = predict(tree, test_sample1)
print("Prediction for Test Sample 1:", prediction1)

Random Forest-
# Random Forest Algorithm on Sonar Dataset
from random import seed
from random import randrange
from csv import reader
from math import sqrt

# Load a CSV file
def load_csv(filename):
	dataset = list()
	with open(filename, 'r') as file:
		csv_reader = reader(file)
		for row in csv_reader:
			if not row:
				continue
			dataset.append(row)
	return dataset

# # Convert string column to float
# def str_column_to_float(dataset, column):
# 	for row in dataset:
# 		row[column] = float(row[column].strip())

# Convert string column to integer
def str_column_to_int(dataset, column):
	class_values = [row[column] for row in dataset]
	unique = set(class_values)
	lookup = dict()
	for i, value in enumerate(unique):
		lookup[value] = i
	for row in dataset:
		row[column] = lookup[row[column]]
	return lookup

# Split a dataset into k folds
def cross_validation_split(dataset, n_folds):
	dataset_split = list()
	dataset_copy = list(dataset)
	fold_size = int(len(dataset) / n_folds)
	for i in range(n_folds):
		fold = list()
		while len(fold) < fold_size:
			index = randrange(len(dataset_copy))
			fold.append(dataset_copy.pop(index))
		dataset_split.append(fold)
	return dataset_split

# Calculate accuracy percentage
def accuracy_metric(actual, predicted):
	correct = 0
	for i in range(len(actual)):
		if actual[i] == predicted[i]:
			correct += 1
	return correct / float(len(actual)) * 100.0

# Evaluate an algorithm using a cross validation split
def evaluate_algorithm(dataset, algorithm, n_folds, *args):
	folds = cross_validation_split(dataset, n_folds)
	scores = list()
	for fold in folds:
		train_set = list(folds)
		train_set.remove(fold)
		train_set = sum(train_set, [])
		test_set = list()
		for row in fold:
			row_copy = list(row)
			test_set.append(row_copy)
			row_copy[-1] = None
		predicted = algorithm(train_set, test_set, *args)
		actual = [row[-1] for row in fold]
		accuracy = accuracy_metric(actual, predicted)
		scores.append(accuracy)
	return scores

# Split a dataset based on an attribute and an attribute value
def test_split(index, value, dataset):
	left, right = list(), list()
	for row in dataset:
		if row[index] < value:
			left.append(row)
		else:
			right.append(row)
	return left, right

# Calculate the Gini index for a split dataset
def gini_index(groups, classes):
	# count all samples at split point
	n_instances = float(sum([len(group) for group in groups]))
	# sum weighted Gini index for each group
	gini = 0.0
	for group in groups:
		size = float(len(group))
		# avoid divide by zero
		if size == 0:
			continue
		score = 0.0
		# score the group based on the score for each class
		for class_val in classes:
			p = [row[-1] for row in group].count(class_val) / size
			score += p * p
		# weight the group score by its relative size
		gini += (1.0 - score) * (size / n_instances)
	return gini

# Select the best split point for a dataset
def get_split(dataset, n_features):
	class_values = list(set(row[-1] for row in dataset))
	b_index, b_value, b_score, b_groups = 999, 999, 999, None
	features = list()
	while len(features) < n_features:
		index = randrange(len(dataset[0])-1)
		if index not in features:
			features.append(index)
	for index in features:
		for row in dataset:
			groups = test_split(index, row[index], dataset)
			gini = gini_index(groups, class_values)
			if gini < b_score:
				b_index, b_value, b_score, b_groups = index, row[index], gini, groups
	return {'index':b_index, 'value':b_value, 'groups':b_groups}

# Create a terminal node value
def to_terminal(group):
	outcomes = [row[-1] for row in group]
	return max(set(outcomes), key=outcomes.count)

# Create child splits for a node or make terminal
def split(node, max_depth, min_size, n_features, depth):
	left, right = node['groups']
	del(node['groups'])
	# check for a no split
	if not left or not right:
		node['left'] = node['right'] = to_terminal(left + right)
		return
	# check for max depth
	if depth >= max_depth:
		node['left'], node['right'] = to_terminal(left), to_terminal(right)
		return
	# process left child
	if len(left) <= min_size:
		node['left'] = to_terminal(left)
	else:
		node['left'] = get_split(left, n_features)
		split(node['left'], max_depth, min_size, n_features, depth+1)
	# process right child
	if len(right) <= min_size:
		node['right'] = to_terminal(right)
	else:
		node['right'] = get_split(right, n_features)
		split(node['right'], max_depth, min_size, n_features, depth+1)

# Build a decision tree
def build_tree(train, max_depth, min_size, n_features):
	root = get_split(train, n_features)
	split(root, max_depth, min_size, n_features, 1)
	return root

# Make a prediction with a decision tree
def predict(node, row):
	if row[node['index']] < node['value']:
		if isinstance(node['left'], dict):
			return predict(node['left'], row)
		else:
			return node['left']
	else:
		if isinstance(node['right'], dict):
			return predict(node['right'], row)
		else:
			return node['right']

# Create a random subsample from the dataset with replacement
def subsample(dataset, ratio):
	sample = list()
	n_sample = round(len(dataset) * ratio)
	while len(sample) < n_sample:
		index = randrange(len(dataset))
		sample.append(dataset[index])
	return sample

# Make a prediction with a list of bagged trees
def bagging_predict(trees, row):
	predictions = [predict(tree, row) for tree in trees]
	return max(set(predictions), key=predictions.count)

# Random Forest Algorithm
def random_forest(train, test, max_depth, min_size, sample_size, n_trees, n_features):
	trees = list()
	for i in range(n_trees):
		sample = subsample(train, sample_size)
		tree = build_tree(sample, max_depth, min_size, n_features)
		trees.append(tree)
	predictions = [bagging_predict(trees, row) for row in test]
	return(predictions)

# Test the random forest algorithm
seed(2)
# load and prepare data
filename = 'Social_Network_Ads.csv'
dataset = load_csv(filename)
# # convert string attributes to integers
# for i in range(0, len(dataset[0])-1):
# 	str_column_to_float(dataset, i)
# convert class column to integers
str_column_to_int(dataset, len(dataset[0])-1)
# evaluate algorithm
n_folds = 5
max_depth = 10
min_size = 1
sample_size = 1.0
n_features = int(sqrt(len(dataset[0])-1))
for n_trees in [1, 5, 10]:
	scores = evaluate_algorithm(dataset, random_forest, n_folds, max_depth, min_size, sample_size, n_trees, n_features)
	print('Trees: %d' % n_trees)
	print('Scores: %s' % scores)
	print('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores))))

random forest-
import pandas as pd
import numpy as np
from collections import Counter
import random

# -----------------------------
# Utility Functions
# -----------------------------

def gini_index(groups, classes):
    n_instances = float(sum([len(group) for group in groups]))
    gini = 0.0
    
    for group in groups:
        size = float(len(group))
        if size == 0:
            continue
        score = 0.0
        labels = [row[-1] for row in group]
        for class_val in classes:
            p = labels.count(class_val) / size
            score += p * p
        gini += (1 - score) * (size / n_instances)
    return gini

def split_dataset(index, value, dataset):
    left, right = [], []
    for row in dataset:
        if row[index] < value:
            left.append(row)
        else:
            right.append(row)
    return left, right

def get_split(dataset, n_features):
    class_values = list(set(row[-1] for row in dataset))
    b_index, b_value, b_score, b_groups = None, None, float('inf'), None
    features = random.sample(range(len(dataset[0]) - 1), n_features)
    
    for index in features:
        for row in dataset:
            groups = split_dataset(index, row[index], dataset)
            gini = gini_index(groups, class_values)
            if gini < b_score:
                b_index, b_value, b_score, b_groups = index, row[index], gini, groups
    return {'index': b_index, 'value': b_value, 'groups': b_groups}

def to_terminal(group):
    outcomes = [row[-1] for row in group]
    return Counter(outcomes).most_common(1)[0][0]

def split(node, max_depth, min_size, n_features, depth):
    left, right = node['groups']
    del(node['groups'])
    
    # If no split
    if not left or not right:
        node['left'] = node['right'] = to_terminal(left + right)
        return
    
    # Check for max depth
    if depth >= max_depth:
        node['left'], node['right'] = to_terminal(left), to_terminal(right)
        return
    
    # Process left
    if len(left) <= min_size:
        node['left'] = to_terminal(left)
    else:
        node['left'] = get_split(left, n_features)
        split(node['left'], max_depth, min_size, n_features, depth + 1)
    
    # Process right
    if len(right) <= min_size:
        node['right'] = to_terminal(right)
    else:
        node['right'] = get_split(right, n_features)
        split(node['right'], max_depth, min_size, n_features, depth + 1)

def build_tree(train, max_depth, min_size, n_features):
    root = get_split(train, n_features)
    split(root, max_depth, min_size, n_features, 1)
    return root

def predict(node, row):
    if row[node['index']] < node['value']:
        if isinstance(node['left'], dict):
            return predict(node['left'], row)
        else:
            return node['left']
    else:
        if isinstance(node['right'], dict):
            return predict(node['right'], row)
        else:
            return node['right']

def subsample(dataset, ratio):
    sample = []
    n_sample = round(len(dataset) * ratio)
    while len(sample) < n_sample:
        index = random.randrange(len(dataset))
        sample.append(dataset[index])
    return sample

def random_forest(train, test, max_depth, min_size, sample_size, n_trees, n_features):
    trees = []
    for _ in range(n_trees):
        sample = subsample(train, sample_size)
        tree = build_tree(sample, max_depth, min_size, n_features)
        trees.append(tree)
    
    predictions = [bagging_predict(trees, row) for row in test]
    return predictions

def bagging_predict(trees, row):
    predictions = [predict(tree, row) for tree in trees]
    return Counter(predictions).most_common(1)[0][0]

def accuracy_metric(actual, predicted):
    correct = sum(1 for a, p in zip(actual, predicted) if a == p)
    return correct / len(actual)

# -----------------------------
# Example: Run on Diabetes Dataset
# -----------------------------

# Load dataset
df = pd.read_csv('bankloan.csv')
data = df.values.tolist()

# Train-test split (80-20)
random.shuffle(data)
split_index = int(len(data) * 0.8)
train_data, test_data = data[:split_index], data[split_index:]

# Extract labels
actual = [row[-1] for row in test_data]

# Run Random Forest
n_trees = 4
max_depth = 10
min_size = 5
sample_size = 1.0
n_features = int(np.sqrt(len(data[0]) - 1))  # Common heuristic

predictions = random_forest(train_data, test_data, max_depth, min_size, sample_size, n_trees, n_features)

# Accuracy
acc = accuracy_metric(actual, predictions)
print(f"Random Forest Accuracy: {acc:.4f}")


Adaboost
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split

# ---------------------
# Step 1: Decision Stump
# ---------------------
class DecisionStump:
    def __init__(self):
        self.feature_index = None
        self.threshold = None
        self.polarity = 1
        self.alpha = None

    def predict(self, X):
        n_samples = X.shape[0]
        predictions = np.ones(n_samples)
        if self.polarity == 1:
            predictions[X[:, self.feature_index] < self.threshold] = -1
        else:
            predictions[X[:, self.feature_index] >= self.threshold] = -1
        return predictions

# ---------------------
# Step 2: AdaBoost Classifier
# ---------------------
class AdaBoost:
    def __init__(self, n_clf=5):
        self.n_clf = n_clf
        self.clfs = []

    def fit(self, X, y):
        n_samples, n_features = X.shape
        y = np.where(y == 0, -1, 1)

        w = np.full(n_samples, 1 / n_samples)

        for _ in range(self.n_clf):
            clf = DecisionStump()
            min_error = float('inf')

            for feature in range(n_features):
                feature_values = np.unique(X[:, feature])
                for threshold in feature_values:
                    for polarity in [1, -1]:
                        predictions = np.ones(n_samples)
                        if polarity == 1:
                            predictions[X[:, feature] < threshold] = -1
                        else:
                            predictions[X[:, feature] >= threshold] = -1

                        misclassified = w[y != predictions]
                        error = sum(misclassified)

                        if error < min_error:
                            clf.polarity = polarity
                            clf.threshold = threshold
                            clf.feature_index = feature
                            min_error = error

            EPS = 1e-10
            clf.alpha = 0.5 * np.log((1.0 - min_error) / (min_error + EPS))

            predictions = clf.predict(X)
            w *= np.exp(-clf.alpha * y * predictions)
            w /= np.sum(w)

            self.clfs.append(clf)

    def predict(self, X):
        clf_preds = [clf.alpha * clf.predict(X) for clf in self.clfs]
        y_pred = np.sign(np.sum(clf_preds, axis=0))
        return np.where(y_pred == -1, 0, 1)

# ---------------------
# Step 3: Example Usage
# ---------------------

# Load and clean data
df = pd.read_csv('data.csv')

# Convert diagnosis to binary
df['diagnosis'] = df['diagnosis'].map({'M': 1, 'B': 0})
df = df.drop(columns=['id', 'Unnamed: 32'], errors='ignore')

# Extract features and target
X = df.drop('diagnosis', axis=1).values
y = df['diagnosis'].values

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train model
model = AdaBoost(n_clf=10)
model.fit(X_train, y_train)

# Predict and evaluate
y_pred = model.predict(X_test)
accuracy = np.mean(y_pred == y_test)

print(f"AdaBoost Accuracy: {accuracy:.4f}")


PCA-
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

# PCA Implementation from scratch
class PCA:
    def __init__(self, n_components):
        self.n_components = n_components
        self.components = None
        self.mean = None

    def fit(self, X):
        self.mean = np.mean(X, axis=0)
        X_centered = X - self.mean
        cov_matrix = np.cov(X_centered.T)
        eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)
        sorted_indices = np.argsort(eigenvalues)[::-1]
        eigenvectors = eigenvectors[:, sorted_indices]
        self.components = eigenvectors[:, :self.n_components]

    def transform(self, X):
        X_centered = X - self.mean
        return np.dot(X_centered, self.components)

# Load Wine Quality dataset
data = pd.read_csv('/content/winequality-red.csv')

# Separate features and target
X = data.drop('quality', axis=1).values
y = data['quality'].values

# Apply PCA
pca = PCA(n_components=2)
pca.fit(X)
X_reduced = pca.transform(X)

# Visualize PCA results colored by wine quality (as discrete labels)
plt.figure(figsize=(8, 6))
for label in np.unique(y):
    plt.scatter(X_reduced[y == label, 0], X_reduced[y == label, 1], label=f"Quality {label}")
plt.xlabel("Principal Component 1")
plt.ylabel("Principal Component 2")
plt.title("PCA on Wine Quality Dataset")
plt.legend()
plt.grid(True)
plt.show()

